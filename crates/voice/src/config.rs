//! Voice configuration types.

use {
    secrecy::Secret,
    serde::{Deserialize, Serialize},
};

/// Top-level voice configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct VoiceConfig {
    pub tts: TtsConfig,
    pub stt: SttConfig,
}

/// Text-to-Speech configuration.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct TtsConfig {
    /// Enable TTS globally.
    pub enabled: bool,

    /// Default provider: "elevenlabs", "openai".
    pub provider: String,

    /// Auto-speak mode.
    pub auto: TtsAutoMode,

    /// Max text length before skipping TTS (characters).
    pub max_text_length: usize,

    /// ElevenLabs-specific settings.
    pub elevenlabs: ElevenLabsConfig,

    /// OpenAI TTS settings.
    pub openai: OpenAiTtsConfig,
}

impl Default for TtsConfig {
    fn default() -> Self {
        Self {
            enabled: false,
            provider: "elevenlabs".into(),
            auto: TtsAutoMode::Off,
            max_text_length: 2000,
            elevenlabs: ElevenLabsConfig::default(),
            openai: OpenAiTtsConfig::default(),
        }
    }
}

/// Auto-speak mode for TTS.
#[derive(Debug, Clone, Default, PartialEq, Eq, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum TtsAutoMode {
    /// Speak all responses.
    Always,
    /// Never auto-speak.
    #[default]
    Off,
    /// Only when user sent voice input.
    Inbound,
    /// Only with explicit [[tts]] markup.
    Tagged,
}

/// ElevenLabs provider configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct ElevenLabsConfig {
    /// API key (from ELEVENLABS_API_KEY env or config).
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        serialize_with = "serialize_option_secret",
        deserialize_with = "deserialize_option_secret"
    )]
    pub api_key: Option<Secret<String>>,

    /// Default voice ID.
    pub voice_id: Option<String>,

    /// Model to use (e.g., "eleven_flash_v2_5" for lowest latency).
    pub model: Option<String>,

    /// Voice stability (0.0 - 1.0).
    pub stability: Option<f32>,

    /// Similarity boost (0.0 - 1.0).
    pub similarity_boost: Option<f32>,
}

/// OpenAI TTS provider configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct OpenAiTtsConfig {
    /// API key (from OPENAI_API_KEY env or config).
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        serialize_with = "serialize_option_secret",
        deserialize_with = "deserialize_option_secret"
    )]
    pub api_key: Option<Secret<String>>,

    /// Voice to use (alloy, echo, fable, onyx, nova, shimmer).
    pub voice: Option<String>,

    /// Model to use (tts-1, tts-1-hd).
    pub model: Option<String>,

    /// Speed (0.25 - 4.0, default 1.0).
    pub speed: Option<f32>,
}

/// Speech-to-Text configuration.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(default)]
pub struct SttConfig {
    /// Enable STT globally.
    pub enabled: bool,

    /// Default provider: "whisper", "groq", "deepgram", "google", "whisper-cli", "sherpa-onnx".
    pub provider: String,

    /// OpenAI Whisper settings.
    pub whisper: WhisperConfig,

    /// Groq (Whisper-compatible) settings.
    pub groq: GroqSttConfig,

    /// Deepgram settings.
    pub deepgram: DeepgramConfig,

    /// Google Cloud Speech-to-Text settings.
    pub google: GoogleSttConfig,

    /// whisper-cli (whisper.cpp) settings.
    pub whisper_cli: WhisperCliConfig,

    /// sherpa-onnx offline settings.
    pub sherpa_onnx: SherpaOnnxConfig,
}

impl Default for SttConfig {
    fn default() -> Self {
        Self {
            enabled: false,
            provider: "whisper".into(),
            whisper: WhisperConfig::default(),
            groq: GroqSttConfig::default(),
            deepgram: DeepgramConfig::default(),
            google: GoogleSttConfig::default(),
            whisper_cli: WhisperCliConfig::default(),
            sherpa_onnx: SherpaOnnxConfig::default(),
        }
    }
}

/// OpenAI Whisper configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct WhisperConfig {
    /// API key (from OPENAI_API_KEY env or config).
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        serialize_with = "serialize_option_secret",
        deserialize_with = "deserialize_option_secret"
    )]
    pub api_key: Option<Secret<String>>,

    /// Model to use (whisper-1).
    pub model: Option<String>,

    /// Language hint (ISO 639-1 code).
    pub language: Option<String>,
}

/// Groq STT configuration (Whisper-compatible API).
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct GroqSttConfig {
    /// API key (from GROQ_API_KEY env or config).
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        serialize_with = "serialize_option_secret",
        deserialize_with = "deserialize_option_secret"
    )]
    pub api_key: Option<Secret<String>>,

    /// Model to use (e.g., "whisper-large-v3-turbo").
    pub model: Option<String>,

    /// Language hint (ISO 639-1 code).
    pub language: Option<String>,
}

/// Deepgram STT configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct DeepgramConfig {
    /// API key (from DEEPGRAM_API_KEY env or config).
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        serialize_with = "serialize_option_secret",
        deserialize_with = "deserialize_option_secret"
    )]
    pub api_key: Option<Secret<String>>,

    /// Model to use (e.g., "nova-3").
    pub model: Option<String>,

    /// Language hint (e.g., "en-US").
    pub language: Option<String>,

    /// Enable smart formatting (punctuation, capitalization).
    pub smart_format: bool,
}

/// Google Cloud Speech-to-Text configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct GoogleSttConfig {
    /// API key for Google Cloud Speech-to-Text.
    #[serde(
        default,
        skip_serializing_if = "Option::is_none",
        serialize_with = "serialize_option_secret",
        deserialize_with = "deserialize_option_secret"
    )]
    pub api_key: Option<Secret<String>>,

    /// Path to service account JSON file (alternative to API key).
    pub service_account_json: Option<String>,

    /// Language code (e.g., "en-US").
    pub language: Option<String>,

    /// Model variant (e.g., "latest_long", "latest_short").
    pub model: Option<String>,
}

/// whisper-cli (whisper.cpp) configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct WhisperCliConfig {
    /// Path to whisper-cli binary. If not set, looks in PATH.
    pub binary_path: Option<String>,

    /// Path to the GGML model file (e.g., "~/.moltis/models/ggml-base.en.bin").
    pub model_path: Option<String>,

    /// Language hint (ISO 639-1 code).
    pub language: Option<String>,
}

/// sherpa-onnx offline configuration.
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
#[serde(default)]
pub struct SherpaOnnxConfig {
    /// Path to sherpa-onnx-offline binary. If not set, looks in PATH.
    pub binary_path: Option<String>,

    /// Path to the ONNX model directory.
    pub model_dir: Option<String>,

    /// Language hint (ISO 639-1 code).
    pub language: Option<String>,
}

// ── Secret serialization helpers ───────────────────────────────────────────

fn serialize_option_secret<S>(
    value: &Option<Secret<String>>,
    serializer: S,
) -> Result<S::Ok, S::Error>
where
    S: serde::Serializer,
{
    use secrecy::ExposeSecret;
    match value {
        Some(secret) => serializer.serialize_some(secret.expose_secret()),
        None => serializer.serialize_none(),
    }
}

fn deserialize_option_secret<'de, D>(deserializer: D) -> Result<Option<Secret<String>>, D::Error>
where
    D: serde::Deserializer<'de>,
{
    let opt: Option<String> = Option::deserialize(deserializer)?;
    Ok(opt.map(Secret::new))
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_tts_config() {
        let config = TtsConfig::default();
        assert!(!config.enabled);
        assert_eq!(config.provider, "elevenlabs");
        assert_eq!(config.auto, TtsAutoMode::Off);
        assert_eq!(config.max_text_length, 2000);
    }

    #[test]
    fn test_default_stt_config() {
        let config = SttConfig::default();
        assert!(!config.enabled);
        assert_eq!(config.provider, "whisper");
    }

    #[test]
    fn test_tts_auto_mode_serde() {
        let json = r#""always""#;
        let mode: TtsAutoMode = serde_json::from_str(json).unwrap();
        assert_eq!(mode, TtsAutoMode::Always);

        let json = r#""off""#;
        let mode: TtsAutoMode = serde_json::from_str(json).unwrap();
        assert_eq!(mode, TtsAutoMode::Off);
    }

    #[test]
    fn test_voice_config_roundtrip() {
        let config = VoiceConfig {
            tts: TtsConfig {
                enabled: true,
                provider: "openai".into(),
                auto: TtsAutoMode::Inbound,
                max_text_length: 1000,
                elevenlabs: ElevenLabsConfig {
                    voice_id: Some("test-voice".into()),
                    ..Default::default()
                },
                openai: OpenAiTtsConfig::default(),
            },
            stt: SttConfig::default(),
        };

        let json = serde_json::to_string(&config).unwrap();
        let parsed: VoiceConfig = serde_json::from_str(&json).unwrap();

        assert!(parsed.tts.enabled);
        assert_eq!(parsed.tts.provider, "openai");
        assert_eq!(parsed.tts.auto, TtsAutoMode::Inbound);
    }
}
